# UMinho Schedule Scraper 

Python script to scrape the University of Minho schedules pages to a JSON file.

## Running

### Install dependencies

##### unidecode

To create short names to subjects, removing accents from chars.
Ex.: Álgebra Linear para a Engenharia -> ÁLE -> ALE

```bash
$ pip install unidecode
```

##### Selenium

Used to scrape the webpage. On this case is impossible use libraries like `beautifulsoup` due the web stack used by UMinho.

```bash
$ pip install selenium
```

##### Geckodriver

A selenium dependency to interact with browsers.

```bash
# Arch
$ pacman -S geckodriver
```

##### Firefox

The browser chosen to run with Selenium was Firefox.

```bash
# Arch
$ pacman -S firefox
```

### Running

Now you can just run and watch. The scrape will be stored at `data/shifts.json`, with the schedule of the 5 years of `Computer Science Engineering`.

```bash
$ python scraper/main.py
```

##### Subjects Short Names

[Calendarium](https://calendario.cesium.di.uminho.pt/) use some short names to easily identify some subjects. This names were chosen on previous versions of `filters.json`. The scrap can be done combining the files `data/filter.json` and `data/shifts.json` from a specific commit (when this files were a manual scrap) from [Calendarium Github Page](https://github.com/cesium/calendarium).

If not founded, `scraper/subjects_short_names.json` will be generated by the schedule scraper. Read more at [subjects short names](./modules/README.md#subjects_short_names).

###### You can add manually names to this list

##### Subject IDs and Filter Ids

[Calendarium](https://calendario.cesium.di.uminho.pt/) use a subject ID and a filterID. On UMinho Courses pages, a list of all subjects, ordered first by year/semesters and next by alphabetic order, and the subject IDs are given. This is everything we need to complete `shifts.json` and generate a basic `filters.json` to Calendarium.

If not founded, `scraper/subjects.json` will be generated by the schedule scraper. Read more at [subjects scraper documentation](./modules/README.md#subject-id-and-a-filter-id-scraper).

###### You can add manually subjects to this list


## Are you facing problems?

Due the framework used by UMinho, sometimes the scraper will crash, because the site is yet rendering, and selenium is already running. Try run again the script and check if the problem persists.

This script use a lot of HTML elements IDs and classes, and, with the past of the years, UM can, for some reason, update the website and crash this script. Open an issue and we will try solve it fast as possible, or, if you have time, try solve it and we will check your PR ;)

