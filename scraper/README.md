# UMinho Schedule Scraper

Python script to scrape the University of Minho schedules pages to a JSON file.

## Running

### Just a Warning ⚠️

Some subjects that aren't present at UMinho webpage or some CeSIUM events need to be added manually.

To get the best possible output edit the following arrays:

* filters at `scraper/modules/create_filters.py`
* manual_subjects at `scraper/modules/subjects_scraper.py`

For a better understanding read [this](https://github.com/cesium/calendarium/tree/master/scraper/modules#subjects-short-name) documentation.

If you gonna scrape the schedules to use at the website maybe is better to delete the "cache files" to a ("maybe") better scrape.

```bash
rm scraper/*.json
```

And finally, the scraper is not perfect, due the Framework used by UMinho. Please read carefully the script output. 

### Install dependencies

```bash
# Python dependecies: (any system with pip)
pip install requests unidecode selenium

# System dependecies:
sudo pacman -S geckodriver firefox # Arch
```

| package     | usage                                                                                                                                      |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| requests    | To download previous commits files from our GitHub page and scrape subjects short names                                                    |
| unidecode   | To create short names to subjects (that weren't scraped), removing accents from chars. Ex.: Álgebra Linear para a Engenharia -> ÁLE -> ALE |
| selenium    | Used to scrape the webpage. On this case is impossible use libraries like `beautifulsoup` due the web stack used by UMinho                 |
| geckodriver | A selenium dependency to interact with browsers                                                                                            |
| firefox     | The browser chosen to run with Selenium was Firefox                                                                                        |

### Running

Now you can just run and watch. The scrape will be stored at `data/shifts.json`, with the schedule of the 5 years of `Computer Science Engineering`.

```bash
$ python scraper/main.py
```

##### Subjects Short Names

[Calendarium](https://calendario.cesium.di.uminho.pt/) use some short names to easily identify some subjects. This names were chosen on previous versions of `filters.json`. The scrap can be done combining the files `data/filter.json` and `data/shifts.json` from a specific commit (when this files were a manual scrap) from [Calendarium Github Page](https://github.com/cesium/calendarium).

If not founded, `scraper/subjects_short_names.json` will be generated by the schedule scraper. Read more at [subjects short names](./modules/README.md#subjects_short_names).

###### You can add manually names to this list

##### Subject IDs and Filter Ids

[Calendarium](https://calendario.cesium.di.uminho.pt/) use a subject ID and a filterID. On UMinho Courses pages, a list of all subjects, ordered first by year/semesters and next by alphabetic order, and the subject IDs are given. This is everything we need to complete `shifts.json` and generate a basic `filters.json` to Calendarium.

If not founded, `scraper/subjects.json` will be generated by the schedule scraper. Read more at [subjects scraper documentation](./modules/README.md#subject-id-and-a-filter-id-scraper).

###### You can add manually subjects to this list

## Are you facing problems?

Due the framework used by UMinho, sometimes the scraper will crash, because the site is yet rendering, and selenium is already running. Try run again the script and check if the problem persists.

This script use a lot of HTML elements IDs and classes, and, with the past of the years, UM can, for some reason, update the website and crash this script. Open an issue and we will try solve it fast as possible, or, if you have time, try solve it and we will check your PR ;)
