## Subjects Short Name

##### (subjects_short_names_scraper.py)

[Calendarium](https://calendario.cesium.di.uminho.pt/) use some short names to easily identify some subjects. This names were chosen on previous versions of `filters.json`. 

### Scraping this values

The scrap can be done combining the files `data/filter.json` and `data/shifts.json` from a specific commit (when this files were a manual scrap) from [Calendarium Github Page](https://github.com/cesium/calendarium).

#### Adding manual values

If for some reason you want add some subjects (a new one) to this scrap, you can edit the dictionary `manual_subject_names` at `scraper/modules/subjects_short_names_scraper.py` file. Follow the next schema:

```python
manual_subject_names = {
  str: { # subject Id 
    "name": str, # complete name
    "short_name": # short name
  }
}
```

#### Output

If not founded, `scraper/subjects_short_names.json` will be generated by the schedule scraper.

## Subject ID and a Filter ID Scraper

##### (subjects_scraper.py)

[Calendarium](https://calendario.cesium.di.uminho.pt/) uses a subject ID and a filterID. The first is given by the university, the second is calculated with:

```python
filterId = f"{university_year}{university_semester}{subject_code}"
```

Where the `subject code` is the position of the subject in an alphabetic ordered list. For example:

```python
# 1st year & 1st semester subjects:
["Álgebra", "Cálculo", "Tópicos Matemática"]
```

The `filterID` of `Tópicos Matemática` will be `113`.

### Scraping this values

On UMinho Courses pages, a list of all subjects, ordered first by year/semesters and next by alphabetic order, and the subject IDs are given. This is everything we need to complete `shifts.json` and generate a basic `filters.json` to Calendarium.

#### Adding manual values

If for some reason you want add some subjects (a not scraped one) to this list, you have a section to do that. Search the next header on the code and follow the next schema:

```python
# ===============================
# Make here your manual editions
# ===============================

print(f"\n\033[91m\033[1mWARNING:\033[0m Adding manually `{subject name}` subject.")
subjects.append({
    "id": int, # filterID
    "subjectId": int,
    "name": str, # complete subject name
    "short_name": str, # short subject name
    "year": int,
    "semester": int
})

# =====================
```

#### Output

The scrape will be stored at `scraper/subjects.json`.
